**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      |     |
| -------------- | --- |
| Student Names: |     |
| Maheen Raza    |30137445     |
| Chloe Villaranda  | 30097691    |
|                |     |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

In this last assignment, our group looked at creating test suites for two classes: DataUtilities and Range, and these test suites were created using black box testing methods, as we had no access to the internal structure or source code of these classes. 

For assignment 3, we were introduced to the importance of coverage when it comes to our test suites. Understanding, as well as measuring how well our test cases cover the code in the classes provided is an important feature to take into account when testing the behavior of a system, as it gauges an understanding of what our system is actually doing when we execute these tests.

Through this assignment, this idea of code coverage was approached by using different metrics of measuring coverage, whether it be statement, branch/decision, condition or method coverage. 

# 2 Manual data-flow coverage calculations for X and Y methods

## For DataUtilities.calculateColumnTotal:

In order to calculate the DU-pair coverage for the method calculateColumnTotal() in class DataUtilities, I did the following:

### Draw Data Flow Graph:

![Screenshot](DataUtilitiesDataFlow.jpg)

### Def-Use Sets per Statement Chart:

| Variable | Def-line   | Use-line              |
| -------  | ---------- | ----------------------|
| data     | 123        | 124 (predicate)       |
| column   | 123        | 128 (computation)     |
| total    | 125        | 130 (computation)     |
| rowCount | 126        | 127 (predicate)       |
| data     | 123        | 126 (computation)     |
| r        | 127        | 127 (predicate)       |
| r        | 127        | 127 (computation)     |
| n        | 128        | 129 (predicate)       |
| data     | 123        | 128 (computation)     |
| r        | 127        | 128 (computation)     |
| n        | 128        | 130 (computation)     |
| r2       | 133        | 133 (predicate)       |
| r2       | 133        | 133 (computation)     |
| rowCount | 126        | 133 (predicate)       |
| n        | 134        | 135 (predicate)       |
| data     | 123        | 134 (computation)     |
| r2       | 133        | 134 (computation)     |
| column   | 123        | 134 (computation)     |
| total    | 125        | 136 (computation)     |
| n        | 134        | 136 (computation)     |
| total    | 125        | 139 (occurence)       |

### List of all DU-pairs per variable:

#### For data: 
{123, 124}, {123, 126}, {123, 128}, {123, 134}

#### For column: 
{123, 128}, {123, 134}

#### For total: 
{125, 130}, {125, 136}, {125, 139}

#### For rowCount: 
{126, 127}, {126, 133}

#### For r: 
{127, 127}, {127, 127}, {127, 128}

#### For n: 
{128, 129}, {128, 130}, {134, 135}, {134, 136}

#### For r2: 
{133, 133}, {133, 133}, {133, 134}


DU-pair coverage for each test case:

Total DU-pair coverage:

# 3 A detailed description of the testing strategy for the new unit test

Text…

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Text…

# 6 Pros and Cons of coverage tools used and Metrics you report

Text…

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# 8 A discussion on how the team work/effort was divided and managed

Text…

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Text…

# 10 Comments/feedback on the lab itself

Text…
